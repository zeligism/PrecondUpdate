{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "676c92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from math import log2\n",
    "from itertools import cycle, product\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "\n",
    "from plot1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5ea7c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb369278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args(idx=ep, loss=cross_entropy, metric=error, beta1=0.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data logs root directory\n",
    "LOG_DIR = \"../logs/logs_torch\"\n",
    "PLOT_DIR = \"plots_torch\"\n",
    "\n",
    "\n",
    "class Args:\n",
    "    # Loss function: either \"logistic\" regression, or nonlinear least squares ('nllsq')\n",
    "    LOSSES = (\"cross_entropy\",)\n",
    "    # The following should be the same as the one used in run_experiment.py\n",
    "    DATASETS = (\"mnist\", \"cifar-10\")\n",
    "    OPTIMIZERS = (\"SARAH\", \"L-SVRG\", \"Adam\")\n",
    "    MAX_EPOCHS = 50  # Use 2xT used in run_experiment.py\n",
    "    # These are the metrics collected in the data logs\n",
    "    METRICS = (\"loss\", \"gradnorm\", \"error\")\n",
    "    # These are aggregators for comparing multi-seed runs\n",
    "    AGGS = (\"mean\", \"median\")\n",
    "    # These are the logs columns: effective passes + metrics + walltime\n",
    "    LOG_COLS = [\"ep\", \"loss\", \"gradnorm\", \"error\", \"time\"]\n",
    "    DATA_INDICES = [0, 1, 2, 3, 5]  # indices corresponding to chosen cols in logs\n",
    "    # These are the hyperparameters of interest\n",
    "    ARG_COLS = [\"lr\", \"alpha\", \"beta2\", \"precond\"]\n",
    "\n",
    "    # Choose loss, metric, and aggregation method\n",
    "    idx = \"ep\"\n",
    "    loss = \"cross_entropy\"\n",
    "    metric = \"error\"\n",
    "    agg = \"mean\"\n",
    "    # Downsample this number of effective passes by averaging them\n",
    "    avg_downsample = 2\n",
    "    # Logs will be filtered for this setting when applicable (USE EXACT STRING VALUE AS IN FILENAME).\n",
    "    filter_args = {\n",
    "        \"beta1\": '0.0',\n",
    "    }\n",
    "    # Ignore all runs containing 'any' of these hyperparams.\n",
    "    ignore_args = {\n",
    "        \"alpha\": (1e-11,),\n",
    "        \"weight_decay\": (0.1,),\n",
    "    }\n",
    "    # Force remove log files that are empty\n",
    "    remove_empty_file = False\n",
    "\n",
    "    def __init__(self, log_dir, plot_dir) -> None:\n",
    "        self.log_dir = log_dir\n",
    "        # self.log_dir = os.path.join(self.log_dir, self.loss)\n",
    "        self.plots_dir = plot_dir\n",
    "        os.makedirs(self.plots_dir, exist_ok=True)\n",
    "        self.as_dict = dict(idx=self.idx, loss=self.loss, metric=self.metric, **self.filter_args)\n",
    "        self.experiment_str = f\"_\".join(f\"{k}_{v}\" for k,v in self.as_dict.items())\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        experiment_repr = f\", \".join(f\"{k}={v}\" for k,v in self.as_dict.items())\n",
    "        return f\"Args({experiment_repr})\"\n",
    "\n",
    "\n",
    "args = Args(log_dir=LOG_DIR, plot_dir=PLOT_DIR)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d40c48",
   "metadata": {},
   "source": [
    "# Gathering data and finding best hyperparameters for each (optimizer, dataset) combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81496a9e-0aa2-4969-a7b2-21081c7e3f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame lengths:\n",
      "('mnist', 'SARAH') -> 4167 data rows -> 83 runs\n",
      "('mnist', 'L-SVRG') -> 4068 data rows -> 81 runs\n",
      "('mnist', 'Adam') -> 936 data rows -> 18 runs\n",
      "('cifar-10', 'SARAH') -> 4193 data rows -> 83 runs\n",
      "('cifar-10', 'L-SVRG') -> 4210 data rows -> 84 runs\n",
      "('cifar-10', 'Adam') -> 936 data rows -> 18 runs\n",
      "Took about 2.41 seconds to gather all these data.\n"
     ]
    }
   ],
   "source": [
    "all_dfs = create_experiments_dataframe(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98f3f7-60e4-403b-92b8-795d8067e530",
   "metadata": {},
   "source": [
    "## Get best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca59c937-0832-4f7f-a48e-2e39b74d05a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best hyperparams for ('mnist', 'SARAH')\n",
      "Finding best hyperparams for ('mnist', 'L-SVRG')\n",
      "Finding best hyperparams for ('mnist', 'Adam')\n",
      "Finding best hyperparams for ('cifar-10', 'SARAH')\n",
      "Finding best hyperparams for ('cifar-10', 'L-SVRG')\n",
      "Finding best hyperparams for ('cifar-10', 'Adam')\n"
     ]
    }
   ],
   "source": [
    "best_dfs, best_dfs_fixed_args = find_all_best_hyperparams(args, all_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bb07b",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130b8ea",
   "metadata": {},
   "source": [
    "## Plot best performance of each optimizer on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af103b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('mnist', 'Adam')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'Adam')...\n",
      "Took about 7.75 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "plot_best_perfs(args, best_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fe2bc",
   "metadata": {},
   "source": [
    "## Plot best performance given a fixed value of either $\\alpha$, $\\beta$, or $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34ec86ec-b50c-4783-bef8-0ef9eef17caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Took about 0.40 seconds to create this plot.\n",
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Plotting lines for ('mnist', 'Adam')...\n",
      "Plotting lines for ('cifar-10', 'Adam')...\n",
      "Took about 0.62 seconds to create this plot.\n",
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Plotting lines for ('mnist', 'Adam')...\n",
      "Plotting lines for ('cifar-10', 'Adam')...\n",
      "Took about 0.58 seconds to create this plot.\n",
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Took about 0.39 seconds to create this plot.\n",
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Plotting lines for ('mnist', 'Adam')...\n",
      "Plotting lines for ('cifar-10', 'Adam')...\n",
      "Took about 0.67 seconds to create this plot.\n",
      "Plotting lines for ('mnist', 'SARAH')...\n",
      "Plotting lines for ('cifar-10', 'SARAH')...\n",
      "Plotting lines for ('mnist', 'L-SVRG')...\n",
      "Plotting lines for ('cifar-10', 'L-SVRG')...\n",
      "Plotting lines for ('mnist', 'Adam')...\n",
      "Plotting lines for ('cifar-10', 'Adam')...\n",
      "Took about 0.57 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "plot_best_perfs_given_fixed_arg(args, best_dfs_fixed_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5bcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
