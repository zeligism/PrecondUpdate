{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "676c92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from math import log2\n",
    "from itertools import cycle, product\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "MARKERS = (',', '+', '.', 'o', '*', \"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5ea7c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "83e9552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data logs root directory\n",
    "LOG_DIR = \"logs_logistic\"\n",
    "\n",
    "# The following should be the same as the one used in run_experiment.py\n",
    "DATASETS = (\"a9a\", \"w8a\", \"rcv1\", \"real-sim\",)\n",
    "OPTIMIZERS = (\"SGD\", \"Adam\", \"SARAH\", \"L-SVRG\")\n",
    "T = 100  # Use 2xT used in run_experiment.py\n",
    "\n",
    "# These are the metrics collected in the data logs\n",
    "METRICS = (\"loss\", \"gradnorm\", \"error\")\n",
    "METRIC = \"loss\"  # choose metric\n",
    "\n",
    "# These are aggregators for comparing multi-seed runs\n",
    "AGGS = (\"mean\", \"median\")\n",
    "AGG = \"mean\"  # choose aggregator\n",
    "\n",
    "# Downsample this number of effective passes by averaging them\n",
    "AVG_DOWNSAMPLE = 5\n",
    "\n",
    "# These are the logs columns: effective passes + metrics\n",
    "LOG_COLS = [\"ep\"] + list(METRICS)\n",
    "\n",
    "# These are the hyperparameters of interest\n",
    "ARG_COLS = [\"lr\", \"BS\", \"precond\", \"alpha\"]\n",
    "\n",
    "# Plots will be generated for this hyperparams/args setting.\n",
    "# 'corrupt' should be the scale/suffix of the dataset as a string or 'none'.\n",
    "FILTER_ARGS = {\n",
    "    \"corrupt\": \"none\",\n",
    "    #\"corrupt\": \"(-3,3)\",\n",
    "    \"weight_decay\": 0.1,\n",
    "}\n",
    "\n",
    "# Ignore all runs containing 'any' of these hyperparams.\n",
    "IGNORE_ARGS = {\n",
    "    \"alpha\": [1e-9],\n",
    "    #\"alpha\": [1e-1, 1e-3, 1e-7, 1e-9],\n",
    "    \"BS\": [2048],\n",
    "    \"gamma\": [2**-16, 2**-18, 2**-20],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df62d34",
   "metadata": {},
   "source": [
    "### Utility functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8bee91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore(args_dict):\n",
    "    return any(args_dict[arg] in IGNORE_ARGS[arg]\n",
    "               for arg in IGNORE_ARGS.keys() if arg in args_dict)\n",
    "\n",
    "\n",
    "def loaddata(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def contain_dict(dict1, dict2):\n",
    "    return all(dict1[k] == v for k, v in dict2.items() if k in dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d40c48",
   "metadata": {},
   "source": [
    "# Gathering data and finding best hyperparameters for each (optimizer, dataset) combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "835d9d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unpack_args(fname):\n",
    "    \"\"\"\n",
    "    Recover all args given file path.\n",
    "    \"\"\"\n",
    "    args = {}\n",
    "    # unpack path\n",
    "    dirname, logname = os.path.split(fname)\n",
    "    logdir, args[\"dataset\"] = os.path.split(dirname)\n",
    "    # parse args\n",
    "    args[\"optimizer\"], argstr = logname.split(\"(\")\n",
    "    argstr, _ = argstr.split(\")\")  # remove ').pkl'\n",
    "    args_dict = {k:v for k,v in [s.split(\"=\") for s in argstr.split(\",\")]}\n",
    "\n",
    "    # Extract args\n",
    "    if args[\"dataset\"][-1] == \")\":\n",
    "        args[\"corrupt\"] = args[\"dataset\"][args[\"dataset\"].index(\"(\"):]\n",
    "    else:\n",
    "        # It is very unlikely that the original dataset name will end with ')'\n",
    "        args[\"corrupt\"] = \"none\"\n",
    "\n",
    "    if \"seed\" in args_dict:\n",
    "        args[\"seed\"] = int(args_dict[\"seed\"])\n",
    "    else:\n",
    "        args[\"seed\"] = 0\n",
    "\n",
    "    args[\"BS\"] = int(args_dict[\"BS\"])\n",
    "    args[\"lr\"] = float(args_dict[\"lr\"])\n",
    "    if \"weight_decay\" in args_dict:\n",
    "        args[\"weight_decay\"] = float(args_dict[\"weight_decay\"])\n",
    "    else:\n",
    "        args[\"weight_decay\"] = 0\n",
    "    if \"lr_decay\" in args_dict:\n",
    "        args[\"lr_decay\"] = float(args_dict[\"lr_decay\"])\n",
    "    else:\n",
    "        args[\"lr_decay\"] = 0\n",
    "    if \"p\" in args_dict:\n",
    "        args[\"p\"] = args_dict[\"p\"]\n",
    "    if \"precond\" in args_dict:\n",
    "        args[\"precond\"] = args_dict[\"precond\"]\n",
    "        args[\"beta2\"] = float(args_dict[\"beta2\"])\n",
    "        args[\"alpha\"] = float(args_dict[\"alpha\"])\n",
    "    else:\n",
    "        args[\"precond\"] = \"none\"\n",
    "        args[\"alpha\"] = \"none\"\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_logs(logdir, dataset, optimizer, **filter_args):\n",
    "    \"\"\"\n",
    "    Return all logs in 'logdir' containing the filter hyperparams.\n",
    "    Dataset name should contain feature scaling, if any\n",
    "    e.g. 'dataset' or 'dataset(k_min,k_max)'.\n",
    "    \n",
    "    Returns the data in the log file and its arguments/hyperparams.\n",
    "    \"\"\"\n",
    "    remove_empty_data = False\n",
    "    # Add\n",
    "    if \"corrupt\" in filter_args and filter_args['corrupt'] != \"none\":\n",
    "        # Add scale suffix to specify dataset    \n",
    "        dataset += filter_args['corrupt']\n",
    "    else:\n",
    "        # No setting specified, use wildcard to match all suffixes\n",
    "        dataset += \"*\"\n",
    "    # Find all files matching this pattern\n",
    "    for fname in glob.glob(f\"{logdir}/{dataset}/{optimizer}(*).pkl\"):\n",
    "        exp_args = unpack_args(fname)\n",
    "        # Skip if filter_args do not match args of this file\n",
    "        if not contain_dict(exp_args, filter_args):\n",
    "            continue\n",
    "        # Load data\n",
    "        data = loaddata(fname)\n",
    "        # Handle empty data files\n",
    "        if len(data) == 0:\n",
    "            print(fname, \"has no data!\")\n",
    "            \"\"\"\n",
    "            if \"y\" == input(\"Remove empty log files in the future? (y/n)\"):\n",
    "                remove_empty_data = True\n",
    "            if remove_empty_data:\n",
    "                try:\n",
    "                    print(\"Removing\", fname)\n",
    "                    os.remove(fname)\n",
    "                except OSError as e:\n",
    "                    print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "            \"\"\"\n",
    "            continue\n",
    "        # @XXX: hack to correct wrong initial ep>0 for L-SVRG\n",
    "        ep0 = data[0,0]\n",
    "        if ep0 > 0.:\n",
    "            data[:,0] -= ep0\n",
    "        yield data, exp_args\n",
    "\n",
    "        \n",
    "# Gather data\n",
    "all_dfs = {}\n",
    "start_time = time.time()\n",
    "for exp in product(DATASETS, OPTIMIZERS):\n",
    "    exp_df = pd.DataFrame()\n",
    "    # Get all log data given the experiment and filter args\n",
    "    for data, args in get_logs(LOG_DIR, *exp, **FILTER_ARGS):\n",
    "        if ignore(args):\n",
    "            continue\n",
    "        # Get experiment log data\n",
    "        df = pd.DataFrame(data[:, :4], columns=LOG_COLS)\n",
    "        # Get args of interest\n",
    "        for col in ARG_COLS:\n",
    "            df[col] = args[col]\n",
    "        # Downsample by averaging metrics every AVG_DOWNSAMPLE epoch.\n",
    "        df[\"ep\"] = np.ceil(df[\"ep\"] / AVG_DOWNSAMPLE) * AVG_DOWNSAMPLE\n",
    "        df = df.groupby([\"ep\"] + ARG_COLS).mean().reset_index()\n",
    "        # Get data up to the prespecified epoch T\n",
    "        df = df[df[\"ep\"] <= T]\n",
    "        # @TODO: is this efficient?\n",
    "        exp_df = exp_df.append(df, ignore_index=True)\n",
    "    # Record all runs of exp in a single dataframe\n",
    "    all_dfs[exp] = exp_df\n",
    "\n",
    "    if len(exp_df) == 0:\n",
    "        print(\"No log data found for this experiment!\")\n",
    "        print(\"- Experiment:\", exp)\n",
    "        print(\"- filter_args:\", FILTER_ARGS)\n",
    "        continue\n",
    "data_gather_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "642e18ad-301b-4784-a52d-db7a52e952c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame lengths:\n",
      "('a9a', 'SGD') -> 9240 data rows -> 92 runs\n",
      "('a9a', 'Adam') -> 2310 data rows -> 23 runs\n",
      "('a9a', 'SARAH') -> 9060 data rows -> 90 runs\n",
      "('a9a', 'L-SVRG') -> 9240 data rows -> 92 runs\n",
      "('w8a', 'SGD') -> 9240 data rows -> 92 runs\n",
      "('w8a', 'Adam') -> 2310 data rows -> 23 runs\n",
      "('w8a', 'SARAH') -> 9018 data rows -> 90 runs\n",
      "('w8a', 'L-SVRG') -> 9240 data rows -> 92 runs\n",
      "('rcv1', 'SGD') -> 9240 data rows -> 92 runs\n",
      "('rcv1', 'Adam') -> 2310 data rows -> 23 runs\n",
      "('rcv1', 'SARAH') -> 9109 data rows -> 91 runs\n",
      "('rcv1', 'L-SVRG') -> 9240 data rows -> 92 runs\n",
      "('real-sim', 'SGD') -> 9240 data rows -> 92 runs\n",
      "('real-sim', 'Adam') -> 2310 data rows -> 23 runs\n",
      "('real-sim', 'SARAH') -> 8939 data rows -> 89 runs\n",
      "('real-sim', 'L-SVRG') -> 9240 data rows -> 92 runs\n",
      "Took about 21.92 seconds to gather all these data.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data frame lengths:\")\n",
    "for exp, df in all_dfs.items():\n",
    "    print(f\"{exp} -> {len(df)} data rows -> {len(df) // T} runs\")\n",
    "print(f\"Took about {data_gather_time:.2f} seconds to gather all these data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "81496a9e-0aa2-4969-a7b2-21081c7e3f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a9a', 'SGD')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>precond</th>\n",
       "      <th>alpha</th>\n",
       "      <th>loss</th>\n",
       "      <th>gradnorm</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.681324</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.659349</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.640548</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.624343</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9235</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.326405</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.153126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9236</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.326265</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.152855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.326131</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.152689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.325972</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.152588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9239</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.325871</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.152623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ep        lr   BS     precond alpha      loss  gradnorm     error\n",
       "0       0.0  0.000061  128  hutchinson   0.1  0.693147  0.032853  0.500000\n",
       "1       5.0  0.000061  128  hutchinson   0.1  0.681324  0.030438  0.240810\n",
       "2      10.0  0.000061  128  hutchinson   0.1  0.659349  0.025996  0.240810\n",
       "3      15.0  0.000061  128  hutchinson   0.1  0.640548  0.022276  0.240810\n",
       "4      20.0  0.000061  128  hutchinson   0.1  0.624343  0.019152  0.240810\n",
       "...     ...       ...  ...         ...   ...       ...       ...       ...\n",
       "9235   80.0  0.250000  128        none  none  0.326405  0.000005  0.153126\n",
       "9236   85.0  0.250000  128        none  none  0.326265  0.000005  0.152855\n",
       "9237   90.0  0.250000  128        none  none  0.326131  0.000005  0.152689\n",
       "9238   95.0  0.250000  128        none  none  0.325972  0.000003  0.152588\n",
       "9239  100.0  0.250000  128        none  none  0.325871  0.000004  0.152623\n",
       "\n",
       "[9240 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a9a', 'Adam')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>precond</th>\n",
       "      <th>alpha</th>\n",
       "      <th>loss</th>\n",
       "      <th>gradnorm</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.490661</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.218952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.376919</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.170199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.349499</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.160001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.338260</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.156795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>80.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.559364</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.185843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>85.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.576452</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.188797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>90.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.554361</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.189317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>95.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.587502</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.195245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.186239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2310 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ep        lr   BS precond alpha      loss  gradnorm     error\n",
       "0       0.0  0.000977  128    none  none  0.693147  0.032853  0.500000\n",
       "1       5.0  0.000977  128    none  none  0.490661  0.005833  0.218952\n",
       "2      10.0  0.000977  128    none  none  0.376919  0.000285  0.170199\n",
       "3      15.0  0.000977  128    none  none  0.349499  0.000067  0.160001\n",
       "4      20.0  0.000977  128    none  none  0.338260  0.000023  0.156795\n",
       "...     ...       ...  ...     ...   ...       ...       ...       ...\n",
       "2305   80.0  4.000000  128    none  none  0.559364  0.002561  0.185843\n",
       "2306   85.0  4.000000  128    none  none  0.576452  0.003477  0.188797\n",
       "2307   90.0  4.000000  128    none  none  0.554361  0.002683  0.189317\n",
       "2308   95.0  4.000000  128    none  none  0.587502  0.004606  0.195245\n",
       "2309  100.0  4.000000  128    none  none  0.550898  0.002660  0.186239\n",
       "\n",
       "[2310 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a9a', 'SARAH')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>precond</th>\n",
       "      <th>alpha</th>\n",
       "      <th>loss</th>\n",
       "      <th>gradnorm</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.629872</td>\n",
       "      <td>0.020387</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.556290</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.521626</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.502166</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.24080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.650732</td>\n",
       "      <td>0.024280</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9056</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.648360</td>\n",
       "      <td>0.023811</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9057</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.646080</td>\n",
       "      <td>0.023362</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.022914</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9059</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.641603</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0.24081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9060 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ep        lr   BS     precond alpha      loss  gradnorm    error\n",
       "0       0.0  0.000977  128  hutchinson   0.1  0.693147  0.032853  0.50000\n",
       "1       5.0  0.000977  128  hutchinson   0.1  0.629872  0.020387  0.24081\n",
       "2      10.0  0.000977  128  hutchinson   0.1  0.556290  0.007844  0.24081\n",
       "3      15.0  0.000977  128  hutchinson   0.1  0.521626  0.003871  0.24081\n",
       "4      20.0  0.000977  128  hutchinson   0.1  0.502166  0.002625  0.24080\n",
       "...     ...       ...  ...         ...   ...       ...       ...      ...\n",
       "9055   80.0  0.000015  128  hutchinson   0.1  0.650732  0.024280  0.24081\n",
       "9056   85.0  0.000015  128  hutchinson   0.1  0.648360  0.023811  0.24081\n",
       "9057   90.0  0.000015  128  hutchinson   0.1  0.646080  0.023362  0.24081\n",
       "9058   95.0  0.000015  128  hutchinson   0.1  0.643798  0.022914  0.24081\n",
       "9059  100.0  0.000015  128  hutchinson   0.1  0.641603  0.022485  0.24081\n",
       "\n",
       "[9060 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (exp, df) in enumerate(all_dfs.items()):\n",
    "    if i == 3: break\n",
    "    print(exp)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98f3f7-60e4-403b-92b8-795d8067e530",
   "metadata": {},
   "source": [
    "## Get best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ca59c937-0832-4f7f-a48e-2e39b74d05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dfs = {}\n",
    "best_dfs_with_precond = {}\n",
    "best_dfs_without_precond = {}\n",
    "for exp in product(DATASETS, OPTIMIZERS):\n",
    "    exp_df = all_dfs[exp]\n",
    "    # Get last metrics/performance  (supposed to be epoch-smoothed for better results)\n",
    "    max_ep = exp_df.groupby(ARG_COLS, sort=False)[\"ep\"].transform(max)\n",
    "    perf = exp_df[exp_df[\"ep\"] == max_ep].drop(\"ep\", axis=1)\n",
    "    # Find the minimum aggregate metric (based on mean, median, etc.)\n",
    "    def find_best_hyperparams(perf):\n",
    "        if AGG == \"mean\":\n",
    "            agg_perf = perf.groupby(ARG_COLS).mean()\n",
    "        elif AGG == \"median\":\n",
    "            agg_perf = perf.groupby(ARG_COLS).median()\n",
    "        # Get the aggregated perf that minimizes the chosen metric\n",
    "        min_agg_perf = agg_perf[agg_perf[METRIC] == agg_perf.min()[METRIC]]\n",
    "        return min_agg_perf.index\n",
    "    # Get the data associated with the args of the min aggregated metric\n",
    "    exp_df = exp_df.set_index(ARG_COLS)\n",
    "    best_dfs[exp] = exp_df.loc[find_best_hyperparams(perf)]\n",
    "    best_dfs_with_precond[exp] = exp_df.loc[find_best_hyperparams(perf[perf[\"precond\"] == \"hutchinson\"])]\n",
    "    best_dfs_without_precond[exp] = exp_df.loc[find_best_hyperparams(perf[perf[\"precond\"] == \"none\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "36d9874c-6a23-45c9-80f0-67bebd27b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparams for each optimizer on each dataset given the following setting:\n",
      "{'corrupt': 'none', 'weight_decay': 0.1}\n",
      "\n",
      "('a9a', 'SGD')\n",
      "- lr = 2**0\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('a9a', 'Adam')\n",
      "- lr = 2**-8\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('a9a', 'SARAH')\n",
      "- lr = 2**0\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('a9a', 'L-SVRG')\n",
      "- lr = 2**4\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('w8a', 'SGD')\n",
      "- lr = 2**2\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('w8a', 'Adam')\n",
      "- lr = 2**-8\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('w8a', 'SARAH')\n",
      "- lr = 2**0\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('w8a', 'L-SVRG')\n",
      "- lr = 2**-6\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.001\n",
      "\n",
      "('rcv1', 'SGD')\n",
      "- lr = 2**2\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('rcv1', 'Adam')\n",
      "- lr = 2**-10\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('rcv1', 'SARAH')\n",
      "- lr = 2**0\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('rcv1', 'L-SVRG')\n",
      "- lr = 2**-6\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.001\n",
      "\n",
      "('real-sim', 'SGD')\n",
      "- lr = 2**2\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('real-sim', 'Adam')\n",
      "- lr = 2**-10\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('real-sim', 'SARAH')\n",
      "- lr = 2**0\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('real-sim', 'L-SVRG')\n",
      "- lr = 2**2\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparams for each optimizer on each dataset given the following setting:\")\n",
    "print(FILTER_ARGS)\n",
    "print()\n",
    "for exp, df in best_dfs.items():\n",
    "    print(exp)\n",
    "    for arg, val in zip(ARG_COLS, df.index[0]):\n",
    "        if arg == \"lr\":\n",
    "            val = \"2**\" + str(int(log2(val)))\n",
    "        print(f\"- {arg} = {val}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bb07b",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fd0ff",
   "metadata": {},
   "source": [
    "## Plot gradnorm per lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "161b091b-9c0a-48e0-9f37-7ab51ade0273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types\n",
      "ep float64\n",
      "loss float64\n",
      "gradnorm float64\n",
      "error float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Types\")\n",
    "for col in df.columns:\n",
    "    print(col, df[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b7f87599-2e6b-4030-b71e-2455347d9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rates:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2**-10',\n",
       " '2**-12',\n",
       " '2**-14',\n",
       " '2**-16',\n",
       " '2**-2',\n",
       " '2**-4',\n",
       " '2**-6',\n",
       " '2**-8',\n",
       " '2**0',\n",
       " '2**2',\n",
       " '2**4'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Learning rates:\")\n",
    "for exp, df in all_dfs.items():\n",
    "    display(set(\"2**\"+str(int(log2(lr))) for lr in df[\"lr\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "329af229-7514-43cf-a3b8-013508e623f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range\n",
      "ep: (0.0, 100.0)\n",
      "lr: (1.52587890625e-05, 16.0)\n",
      "BS: (128, 128)\n",
      "loss: (0.3247435008914915, inf)\n",
      "gradnorm: (6.487572414774807e-07, inf)\n",
      "error: (0.0, 0.7591904425539757)\n"
     ]
    }
   ],
   "source": [
    "print(\"Range\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes != \"object\":\n",
    "        print(f\"{col}: ({df[col].min():}, {df[col].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d2b7628b-1e89-482a-9cdc-055e14187188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: (0.0, 100.0)\n",
      "lr: (1.52587890625e-05, 16.0)\n",
      "BS: (128, 128)\n",
      "loss: (0.3247435008914915, 1101479772.438126)\n",
      "gradnorm: (6.487572414774807e-07, 3382.825207172173)\n",
      "error: (0.0, 0.7591904425539757)\n"
     ]
    }
   ],
   "source": [
    "# Set inf values to nan and recheck range\n",
    "VERYBIGNUMBER = 10**10\n",
    "df[df == float(\"inf\")] = np.nan\n",
    "df[df[[\"loss\",\"gradnorm\"]] > VERYBIGNUMBER] = np.nan\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes != \"object\":\n",
    "        print(f\"{col}: ({df[col].min():}, {df[col].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "302e0f60-db61-4ed7-bf7f-7f38f554a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for NaNs in each column for each df.\n",
      "ep\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "lr\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "BS\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "precond\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "alpha\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "loss\n",
      "- ('a9a', 'SGD'): 416\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 421\n",
      "- ('a9a', 'L-SVRG'): 412\n",
      "- ('w8a', 'SGD'): 393\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 406\n",
      "- ('w8a', 'L-SVRG'): 404\n",
      "- ('rcv1', 'SGD'): 600\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 600\n",
      "- ('rcv1', 'L-SVRG'): 593\n",
      "- ('real-sim', 'SGD'): 559\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 411\n",
      "- ('real-sim', 'L-SVRG'): 509\n",
      "gradnorm\n",
      "- ('a9a', 'SGD'): 416\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 421\n",
      "- ('a9a', 'L-SVRG'): 409\n",
      "- ('w8a', 'SGD'): 393\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 401\n",
      "- ('w8a', 'L-SVRG'): 403\n",
      "- ('rcv1', 'SGD'): 600\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 600\n",
      "- ('rcv1', 'L-SVRG'): 593\n",
      "- ('real-sim', 'SGD'): 553\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 410\n",
      "- ('real-sim', 'L-SVRG'): 504\n",
      "error\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Check for NaNs in each column for each df.\")\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    for exp, df in all_dfs.items():\n",
    "        print(f\"- {exp}: {df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a63dddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for ('a9a', 'SGD')...\n",
      "Plotting lines for ('w8a', 'SGD')...\n",
      "Plotting lines for ('rcv1', 'SGD')...\n",
      "Plotting lines for ('real-sim', 'SGD')...\n",
      "Plotting lines for ('a9a', 'Adam')...\n",
      "Plotting lines for ('w8a', 'Adam')...\n",
      "Plotting lines for ('rcv1', 'Adam')...\n",
      "Plotting lines for ('real-sim', 'Adam')...\n",
      "Plotting lines for ('a9a', 'SARAH')...\n",
      "Plotting lines for ('w8a', 'SARAH')...\n",
      "Plotting lines for ('rcv1', 'SARAH')...\n",
      "Plotting lines for ('real-sim', 'SARAH')...\n",
      "Plotting lines for ('a9a', 'L-SVRG')...\n",
      "Plotting lines for ('w8a', 'L-SVRG')...\n",
      "Plotting lines for ('rcv1', 'L-SVRG')...\n",
      "Plotting lines for ('real-sim', 'L-SVRG')...\n",
      "Took about 84.07 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Plot data for all optim, datasets, and args\n",
    "fig, axes = plt.subplots(len(OPTIMIZERS), len(DATASETS))\n",
    "fig.set_size_inches(5 * len(DATASETS), 5 * len(OPTIMIZERS))\n",
    "title = r\"$||\\nabla F(w_t)||^2$ per $\\eta$\"\n",
    "plt.suptitle(title)\n",
    "for i, optimizer in enumerate(OPTIMIZERS):\n",
    "    for j, dataset in enumerate(DATASETS):\n",
    "        exp = (dataset, optimizer)\n",
    "        if exp not in all_dfs:\n",
    "            continue\n",
    "        exp_df = all_dfs[exp]\n",
    "        axes[i,j].set_title(rf\"$\\tt{optimizer}({dataset})$\")\n",
    "        # axes[i,j].set_title(rf\"{optimizer}({dataset})\")\n",
    "        # avoid silly problem of inconsistent style across axes\n",
    "        exp_df[\"alpha\"] = exp_df[\"alpha\"].astype(str)\n",
    "        exp_df = exp_df.sort_values(\"alpha\", ascending=False)\n",
    "        print(f\"Plotting lines for {exp}...\")\n",
    "        sns.lineplot(ax=axes[i,j], x=\"ep\", y=\"gradnorm\",\n",
    "                     hue=\"lr\", hue_norm=LogNorm(), palette=\"vlag\",\n",
    "                     #size=\"BS\", sizes=(1, 2),  # @XXX\n",
    "                     style=\"alpha\",\n",
    "                     # plot only for alpha == none and alpha == 0.001 to reduce clutter\n",
    "                     data=exp_df[(exp_df[\"alpha\"] == \"none\") | (exp_df[\"alpha\"] == \"0.001\")])\n",
    "        axes[i,j].set(yscale=\"log\")\n",
    "        axes[i,j].set_ylabel(r\"$||\\nabla F(w_t)||^2$\")\n",
    "        # Set an upper limit since we seem to have crazy values for some runs @TODO: remove those runs?\n",
    "        axes[i,j].set_ylim(top=exp_df[exp_df[\"ep\"] == 0][\"gradnorm\"].max())\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create a string out of filter args and save figure\n",
    "filter_args_str = \",\".join(f\"{k}={v}\" for k,v in FILTER_ARGS.items())\n",
    "plt.savefig(f\"plots/learning_rates({filter_args_str}).pdf\")\n",
    "plt.close()\n",
    "plot_per_lr_time = time.time() - start_time\n",
    "print(f\"Took about {plot_per_lr_time:.2f} seconds to create this plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130b8ea",
   "metadata": {},
   "source": [
    "## Plot best performance of each optimizer on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "af103b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for ('a9a', 'SGD')...\n",
      "Plotting lines for ('a9a', 'Adam')...\n",
      "Plotting lines for ('a9a', 'SARAH')...\n",
      "Plotting lines for ('a9a', 'L-SVRG')...\n",
      "Plotting lines for ('w8a', 'SGD')...\n",
      "Plotting lines for ('w8a', 'Adam')...\n",
      "Plotting lines for ('w8a', 'SARAH')...\n",
      "Plotting lines for ('w8a', 'L-SVRG')...\n",
      "Plotting lines for ('rcv1', 'SGD')...\n",
      "Plotting lines for ('rcv1', 'Adam')...\n",
      "Plotting lines for ('rcv1', 'SARAH')...\n",
      "Plotting lines for ('rcv1', 'L-SVRG')...\n",
      "Plotting lines for ('real-sim', 'SGD')...\n",
      "Plotting lines for ('real-sim', 'Adam')...\n",
      "Plotting lines for ('real-sim', 'SARAH')...\n",
      "Plotting lines for ('real-sim', 'L-SVRG')...\n",
      "Took about 14.36 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Plot 3 rows each one showing some performance metric,\n",
    "# where the columns are the dataset on which the optim is run.\n",
    "fig, axes = plt.subplots(3, len(DATASETS))\n",
    "fig.set_size_inches(5 * len(DATASETS), 5 * 3)\n",
    "plt.suptitle(rf\"Best Performances\")\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "    for optimizer in OPTIMIZERS:\n",
    "        exp = (dataset, optimizer)\n",
    "        if exp not in best_dfs:\n",
    "            continue\n",
    "        # Get hyperparams of best performance of 'optimizer' on 'dataset'\n",
    "        args = {k:v for k,v in zip(best_dfs[exp].index.names, best_dfs[exp].index[0])}\n",
    "        exp_df = best_dfs[exp].reset_index()\n",
    "        # Show power of lr as 2^lr_pow\n",
    "        lr_pow = round(log2(args['lr']))\n",
    "        sublabel = rf\"$\\eta = 2^{{{lr_pow}}}$, $\\alpha={args['alpha']}$\"\n",
    "        label = rf\"{optimizer}({sublabel})\"\n",
    "        print(f\"Plotting lines for {exp}...\")\n",
    "        sns.lineplot(x=\"ep\", y=\"loss\", label=label, ax=axes[0,j], data=exp_df)\n",
    "        sns.lineplot(x=\"ep\", y=\"gradnorm\", label=label, ax=axes[1,j], data=exp_df)\n",
    "        sns.lineplot(x=\"ep\", y=\"error\", label=label, ax=axes[2,j], data=exp_df)\n",
    "    # Loss\n",
    "    axes[0,j].set_title(dataset)\n",
    "    axes[0,j].set_ylabel(r\"$F(w_t)$\")\n",
    "    axes[0,j].set_xlabel(\"Effective Passes\")\n",
    "    axes[0,j].legend()\n",
    "    # Gradnorm\n",
    "    axes[1,j].set(yscale=\"log\")\n",
    "    axes[1,j].set_title(dataset)\n",
    "    axes[1,j].set_ylabel(r\"$||\\nabla F(w_t)||^2$\")\n",
    "    axes[1,j].set_xlabel(\"Effective Passes\")\n",
    "    axes[1,j].legend()\n",
    "    # Error\n",
    "    axes[2,j].set(yscale=\"log\")\n",
    "    axes[2,j].set_title(dataset)\n",
    "    axes[2,j].set_ylabel(\"Error\")\n",
    "    axes[2,j].set_xlabel(\"Effective Passes\")\n",
    "    axes[2,j].legend()\n",
    "    # Set an upper limit since we seem to have crazy values for some runs @TODO: remove those runs?\n",
    "    # axes[0,j].set_ylim(top=exp_df[exp_df[\"ep\"] == 0][\"loss\"].max()*1.1,\n",
    "                       # bottom=exp_df[\"loss\"].min()*0.9)\n",
    "    axes[1,j].set_ylim(top=exp_df[exp_df[\"ep\"] == 0][\"gradnorm\"].max())\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create a string out of filter args and save figure\n",
    "filter_args_str = \",\".join(f\"{k}={v}\" for k,v in FILTER_ARGS.items())\n",
    "plt.savefig(f\"plots/optimizers({filter_args_str}).pdf\")\n",
    "plt.close()\n",
    "plot_best_time = time.time() - start_time\n",
    "print(f\"Took about {plot_best_time:.2f} seconds to create this plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fe2bc",
   "metadata": {},
   "source": [
    "# Generate plots comparing preconditioning vs none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0dbbfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for a9a...\n",
      "Plotting lines for w8a...\n",
      "Plotting lines for rcv1...\n",
      "Plotting lines for real-sim...\n",
      "Took about 23.63 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "fig, axes = plt.subplots(3, len(DATASETS))\n",
    "fig.set_size_inches(5 * len(DATASETS), 5 * 3)\n",
    "plt.suptitle(rf\"Top performance with preconditioning vs. without\")\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "    optim_df = pd.DataFrame()\n",
    "    for optimizer in OPTIMIZERS:\n",
    "        exp = (dataset, optimizer)\n",
    "        if exp not in best_dfs_with_precond or exp not in best_dfs_without_precond:\n",
    "            continue\n",
    "        # Put both dfs together and mark them with the optimizer's name.\n",
    "        # (They already have 'precond' set accordingly.)\n",
    "        exp_df = best_dfs_without_precond[exp].append(best_dfs_with_precond[exp])\n",
    "        exp_df[\"optimizer\"] = optimizer\n",
    "        optim_df = optim_df.append(exp_df)\n",
    "    # reset index and combine precond with gamma\n",
    "    print(f\"Plotting lines for {dataset}...\")\n",
    "    optim_df = optim_df.reset_index()\n",
    "    sns.lineplot(x=\"ep\", y=\"loss\", hue=\"optimizer\", style=\"precond\", ax=axes[0,j], data=optim_df)\n",
    "    sns.lineplot(x=\"ep\", y=\"gradnorm\", hue=\"optimizer\", style=\"precond\", ax=axes[1,j], data=optim_df)\n",
    "    sns.lineplot(x=\"ep\", y=\"error\", hue=\"optimizer\", style=\"precond\", ax=axes[2,j], data=optim_df)\n",
    "    # Loss\n",
    "    axes[0,j].set_title(dataset)\n",
    "    axes[0,j].set_ylabel(r\"$F(w_t)$\")\n",
    "    axes[0,j].set_xlabel(\"Effective Passes\")\n",
    "    # Gradnorm\n",
    "    axes[1,j].set(yscale=\"log\")\n",
    "    axes[1,j].set_title(dataset)\n",
    "    axes[1,j].set_ylabel(r\"$||\\nabla F(w_t)||^2$\")\n",
    "    axes[1,j].set_xlabel(\"Effective Passes\")\n",
    "    # Error\n",
    "    axes[2,j].set(yscale=\"log\")\n",
    "    axes[2,j].set_title(dataset)\n",
    "    axes[2,j].set_ylabel(\"Error\")\n",
    "    axes[2,j].set_xlabel(\"Effective Passes\")\n",
    "fig.tight_layout()\n",
    "\n",
    "filter_args_str = \",\".join(f\"{k}={v}\" for k,v in FILTER_ARGS.items())\n",
    "plt.savefig(f\"plots/compare_optimizers({filter_args_str}).pdf\")\n",
    "plt.close()\n",
    "plot_compare_time = time.time() - start_time\n",
    "print(f\"Took about {plot_compare_time:.2f} seconds to create this plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d9fec6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters using loss metric WITHOUT preconditoning:\n",
      "('a9a', 'SGD'):\tlr = 2^0,\tloss = 0.324835,\tgradnorm = 0.000012,\terror = 0.151017\n",
      "('a9a', 'Adam'):\tlr = 2^-8,\tloss = 0.324696,\tgradnorm = 0.000004,\terror = 0.151011\n",
      "('a9a', 'SARAH'):\tlr = 2^4,\tloss = 0.324294,\tgradnorm = 0.000000,\terror = 0.151226\n",
      "('a9a', 'L-SVRG'):\tlr = 2^4,\tloss = 0.324292,\tgradnorm = 0.000000,\terror = 0.151132\n",
      "('w8a', 'SGD'):\tlr = 2^2,\tloss = 0.107506,\tgradnorm = 0.000000,\terror = 0.054684\n",
      "('w8a', 'Adam'):\tlr = 2^-8,\tloss = 0.108032,\tgradnorm = 0.000000,\terror = 0.053945\n",
      "('w8a', 'SARAH'):\tlr = 2^4,\tloss = 0.107567,\tgradnorm = 0.000000,\terror = 0.054214\n",
      "('w8a', 'L-SVRG'):\tlr = 2^4,\tloss = 0.107503,\tgradnorm = 0.000000,\terror = 0.054685\n",
      "('rcv1', 'SGD'):\tlr = 2^2,\tloss = 0.109916,\tgradnorm = 0.000000,\terror = 0.012690\n",
      "('rcv1', 'Adam'):\tlr = 2^-10,\tloss = 0.115052,\tgradnorm = 0.000000,\terror = 0.008985\n",
      "('rcv1', 'SARAH'):\tlr = 2^4,\tloss = 0.110770,\tgradnorm = 0.000000,\terror = 0.007910\n",
      "('rcv1', 'L-SVRG'):\tlr = 2^4,\tloss = 0.109970,\tgradnorm = 0.000000,\terror = 0.009016\n",
      "('real-sim', 'SGD'):\tlr = 2^2,\tloss = 0.082024,\tgradnorm = 0.000000,\terror = 0.011561\n",
      "('real-sim', 'Adam'):\tlr = 2^-10,\tloss = 0.084527,\tgradnorm = 0.000000,\terror = 0.008355\n",
      "('real-sim', 'SARAH'):\tlr = 2^4,\tloss = 0.082865,\tgradnorm = 0.000000,\terror = 0.008643\n",
      "('real-sim', 'L-SVRG'):\tlr = 2^4,\tloss = 0.085034,\tgradnorm = 0.000000,\terror = 0.015148\n",
      "\n",
      "Best hyperparameters using loss metric WITH preconditoning:\n",
      "('a9a', 'SGD'):\tlr = 2^-8,\talpha = 0.001,\tloss = 0.324825,\tgradnorm = 0.000013,\terror = 0.150809\n",
      "('a9a', 'SARAH'):\tlr = 2^0,\talpha = 0.1,\tloss = 0.324288,\tgradnorm = 0.000000,\terror = 0.151262\n",
      "('a9a', 'L-SVRG'):\tlr = 2^0,\talpha = 0.1,\tloss = 0.324353,\tgradnorm = 0.000000,\terror = 0.151369\n",
      "('w8a', 'SGD'):\tlr = 2^-8,\talpha = 0.001,\tloss = 0.107540,\tgradnorm = 0.000000,\terror = 0.054603\n",
      "('w8a', 'SARAH'):\tlr = 2^0,\talpha = 0.1,\tloss = 0.107411,\tgradnorm = 0.000000,\terror = 0.054511\n",
      "('w8a', 'L-SVRG'):\tlr = 2^-6,\talpha = 0.001,\tloss = 0.107484,\tgradnorm = 0.000000,\terror = 0.054658\n",
      "('rcv1', 'SGD'):\tlr = 2^-8,\talpha = 0.001,\tloss = 0.110046,\tgradnorm = 0.000000,\terror = 0.013145\n",
      "('rcv1', 'SARAH'):\tlr = 2^0,\talpha = 0.1,\tloss = 0.109383,\tgradnorm = 0.000000,\terror = 0.010976\n",
      "('rcv1', 'L-SVRG'):\tlr = 2^-6,\talpha = 0.001,\tloss = 0.109584,\tgradnorm = 0.000000,\terror = 0.009871\n",
      "('real-sim', 'SGD'):\tlr = 2^-8,\talpha = 0.001,\tloss = 0.082058,\tgradnorm = 0.000000,\terror = 0.011755\n",
      "('real-sim', 'SARAH'):\tlr = 2^0,\talpha = 0.1,\tloss = 0.081823,\tgradnorm = 0.000000,\terror = 0.010302\n",
      "('real-sim', 'L-SVRG'):\tlr = 2^2,\talpha = 0.1,\tloss = 0.081848,\tgradnorm = 0.000000,\terror = 0.009902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_best_performances(best_data, show_alpha=True):\n",
    "    for dataset in DATASETS:\n",
    "        for optimizer in OPTIMIZERS:\n",
    "            # Extract best performance metrics for each experiment\n",
    "            exp = (dataset, optimizer)\n",
    "            if exp not in best_data:\n",
    "                continue\n",
    "            if len(best_data[exp].index) == 0:\n",
    "                # Not applicable to exp, likely because it does not have 'precond'\n",
    "                continue\n",
    "            args = {k:v for k,v in zip(best_data[exp].index.names, best_data[exp].index[0])}\n",
    "            exp_df = best_data[exp].reset_index()\n",
    "            loss = exp_df[\"loss\"].iloc[-1]\n",
    "            gradnorm = exp_df[\"gradnorm\"].iloc[-1]\n",
    "            error = exp_df[\"error\"].iloc[-1]\n",
    "            # Print report\n",
    "            print(f\"{exp}:\"\n",
    "                  f\"\\tlr = 2^{str(round(log2(args['lr'])))},\" + \\\n",
    "                  (f\"\\talpha = {args['alpha']},\" if show_alpha else \"\") + \\\n",
    "                  f\"\\tloss = {loss:5f},\"\n",
    "                  f\"\\tgradnorm = {gradnorm:5f},\"\n",
    "                  f\"\\terror = {error:5f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"Best hyperparameters using {METRIC} metric WITHOUT preconditoning:\")\n",
    "display_best_performances(best_dfs_without_precond, show_alpha=False)\n",
    "print(f\"Best hyperparameters using {METRIC} metric WITH preconditoning:\")\n",
    "display_best_performances(best_dfs_with_precond, show_alpha=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85397467-886c-4ae1-9cbc-4f10f26b3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
