{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "676c92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from math import log2\n",
    "from itertools import cycle, product\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "MARKERS = (',', '+', '.', 'o', '*', \"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5ea7c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83e9552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data logs root directory\n",
    "LOG_DIR = \"logs10\"\n",
    "\n",
    "# The following should be the same as the one used in run_experiment.py\n",
    "DATASETS = (\"a9a\", \"w8a\", \"rcv1\", \"real-sim\",)\n",
    "OPTIMIZERS = (\"SGD\", \"Adam\", \"SARAH\", \"L-SVRG\")\n",
    "T = 100  # Use 2xT used in run_experiment.py\n",
    "\n",
    "# These are the metrics collected in the data logs\n",
    "METRICS = (\"loss\", \"gradnorm\", \"error\")\n",
    "METRIC = \"gradnorm\"  # default metric\n",
    "\n",
    "# These are aggregators for comparing multi-seed runs\n",
    "AGGS = (\"mean\", \"median\")\n",
    "AGG = \"mean\"  # default aggregator\n",
    "\n",
    "# Downsample this number of effective passes by averaging them\n",
    "AVG_DOWNSAMPLE = 5\n",
    "\n",
    "# These are the logs columns: effective passes + metrics\n",
    "LOG_COLS = [\"ep\"] + list(METRICS)\n",
    "\n",
    "# These are the hyperparameters of interest\n",
    "ARG_COLS = [\"lr\", \"BS\", \"precond\", \"alpha\"]\n",
    "\n",
    "# Plots will be generated for this hyperparams/args setting.\n",
    "# 'corrupt' should be the suffix of the dataset as a string.\n",
    "FILTER_ARGS = {\n",
    "    #\"corrupt\": \"\",\n",
    "    \"corrupt\": \"(-3,3)\",\n",
    "    \"weight_decay\": 0,\n",
    "}\n",
    "\n",
    "# Ignore all runs containing 'any' of these hyperparams.\n",
    "IGNORE_ARGS = {\n",
    "    \"alpha\": [1e-9],\n",
    "    #\"alpha\": [1e-1, 1e-3, 1e-7, 1e-9],\n",
    "    \"BS\": [2048],\n",
    "    \"gamma\": [2**-16, 2**-18, 2**-20],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df62d34",
   "metadata": {},
   "source": [
    "### Utility functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bee91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore(args_dict):\n",
    "    return any(args_dict[arg] in IGNORE_ARGS[arg]\n",
    "               for arg in IGNORE_ARGS.keys() if arg in args_dict)\n",
    "\n",
    "\n",
    "def loaddata(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def contain_dict(dict1, dict2):\n",
    "    return all(dict1[k] == v for k, v in dict2.items() if k in dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d40c48",
   "metadata": {},
   "source": [
    "# Gathering data and finding best hyperparameters for each (optimizer, dataset) combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "835d9d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unpack_args(fname):\n",
    "    \"\"\"\n",
    "    Recover all args given file path.\n",
    "    \"\"\"\n",
    "    args = {}\n",
    "    # unpack path\n",
    "    dirname, logname = os.path.split(fname)\n",
    "    logdir, args[\"dataset\"] = os.path.split(dirname)\n",
    "    # parse args\n",
    "    args[\"optimizer\"], argstr = logname.split(\"(\")\n",
    "    argstr, _ = argstr.split(\")\")  # remove ').pkl'\n",
    "    args_dict = {k:v for k,v in [s.split(\"=\") for s in argstr.split(\",\")]}\n",
    "\n",
    "    # Extract args\n",
    "    if args[\"dataset\"][-1] == \")\":\n",
    "        args[\"corrupt\"] = args[\"dataset\"][args[\"dataset\"].index(\"(\"):]\n",
    "    else:\n",
    "        # It is very unlikely that the original dataset name will end with ')'\n",
    "        args[\"corrupt\"] = \"none\"\n",
    "\n",
    "    if \"seed\" in args_dict:\n",
    "        args[\"seed\"] = int(args_dict[\"seed\"])\n",
    "    else:\n",
    "        args[\"seed\"] = 0\n",
    "\n",
    "    args[\"BS\"] = int(args_dict[\"BS\"])\n",
    "    args[\"lr\"] = float(args_dict[\"lr\"])\n",
    "    if \"weight_decay\" in args_dict:\n",
    "        args[\"weight_decay\"] = float(args_dict[\"weight_decay\"])\n",
    "    else:\n",
    "        args[\"weight_decay\"] = 0\n",
    "    if \"lr_decay\" in args_dict:\n",
    "        args[\"lr_decay\"] = float(args_dict[\"lr_decay\"])\n",
    "    else:\n",
    "        args[\"lr_decay\"] = 0\n",
    "    if \"p\" in args_dict:\n",
    "        args[\"p\"] = args_dict[\"p\"]\n",
    "    if \"precond\" in args_dict:\n",
    "        args[\"precond\"] = args_dict[\"precond\"]\n",
    "        args[\"beta2\"] = float(args_dict[\"beta2\"])\n",
    "        args[\"alpha\"] = float(args_dict[\"alpha\"])\n",
    "    else:\n",
    "        args[\"precond\"] = \"none\"\n",
    "        args[\"alpha\"] = \"none\"\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_logs(logdir, dataset, optimizer, **filter_args):\n",
    "    \"\"\"\n",
    "    Return all logs in 'logdir' containing the filter hyperparams.\n",
    "    Dataset name should contain feature scaling, if any\n",
    "    e.g. 'dataset' or 'dataset(k_min,k_max)'.\n",
    "    \n",
    "    Returns the data in the log file and its arguments/hyperparams.\n",
    "    \"\"\"\n",
    "    remove_empty_data = False\n",
    "    # Add\n",
    "    if \"corrupt\" in filter_args:\n",
    "        dataset = f\"{dataset}{filter_args['corrupt']}\"\n",
    "    else:\n",
    "        # No setting specified, use wildcard to match all suffixes\n",
    "        dataset += \"*\"\n",
    "    # Find all files matching this pattern\n",
    "    for fname in glob.glob(f\"{logdir}/{dataset}/{optimizer}(*).pkl\"):\n",
    "        exp_args = unpack_args(fname)\n",
    "        # Skip if filter_args do not match args of this file\n",
    "        if not contain_dict(exp_args, filter_args):\n",
    "            continue\n",
    "        # Load data\n",
    "        data = loaddata(fname)\n",
    "        # Handle empty data files\n",
    "        if len(data) == 0:\n",
    "            print(fname, \"has no data!\")\n",
    "            \"\"\"\n",
    "            if \"y\" == input(\"Remove empty log files in the future? (y/n)\"):\n",
    "                remove_empty_data = True\n",
    "            if remove_empty_data:\n",
    "                try:\n",
    "                    print(\"Removing\", fname)\n",
    "                    os.remove(fname)\n",
    "                except OSError as e:\n",
    "                    print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "            \"\"\"\n",
    "            continue\n",
    "        # @XXX: hack to correct wrong initial ep>0 for L-SVRG\n",
    "        ep0 = data[0,0]\n",
    "        if ep0 > 0.:\n",
    "            data[:,0] -= ep0\n",
    "        yield data, exp_args\n",
    "\n",
    "        \n",
    "# Gather data\n",
    "all_dfs = {}\n",
    "start_time = time.time()\n",
    "for exp in product(DATASETS, OPTIMIZERS):\n",
    "    exp_df = pd.DataFrame()\n",
    "    # Get all log data given the experiment and filter args\n",
    "    for data, args in get_logs(LOG_DIR, *exp, **FILTER_ARGS):\n",
    "        if ignore(args):\n",
    "            continue\n",
    "        # Get experiment log data\n",
    "        df = pd.DataFrame(data[:, :4], columns=LOG_COLS)\n",
    "        # Get args of interest\n",
    "        for col in ARG_COLS:\n",
    "            df[col] = args[col]\n",
    "        # Downsample by averaging metrics every AVG_DOWNSAMPLE epoch.\n",
    "        df[\"ep\"] = np.ceil(df[\"ep\"] / AVG_DOWNSAMPLE) * AVG_DOWNSAMPLE\n",
    "        df = df.groupby([\"ep\"] + ARG_COLS).mean().reset_index()\n",
    "        # Get data up to the prespecified epoch T\n",
    "        df = df[df[\"ep\"] <= T]\n",
    "        # @TODO: is this efficient?\n",
    "        exp_df = exp_df.append(df, ignore_index=True)\n",
    "    # Record all runs of exp in a single dataframe\n",
    "    all_dfs[exp] = exp_df\n",
    "\n",
    "    if len(exp_df) == 0:\n",
    "        print(\"No log data found for this experiment!\")\n",
    "        print(\"- Experiment:\", exp)\n",
    "        print(\"- filter_args:\", FILTER_ARGS)\n",
    "        continue\n",
    "    # @TODO: Would it be better to plot these on the go instead of storing them?\n",
    "data_gather_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "642e18ad-301b-4784-a52d-db7a52e952c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame lengths:\n",
      "('a9a', 'SGD') -> 8316 data rows -> 83 runs\n",
      "('a9a', 'Adam') -> 2079 data rows -> 20 runs\n",
      "('a9a', 'SARAH') -> 8185 data rows -> 81 runs\n",
      "('a9a', 'L-SVRG') -> 8316 data rows -> 83 runs\n",
      "('w8a', 'SGD') -> 8295 data rows -> 82 runs\n",
      "('w8a', 'Adam') -> 2079 data rows -> 20 runs\n",
      "('w8a', 'SARAH') -> 8314 data rows -> 83 runs\n",
      "('w8a', 'L-SVRG') -> 8316 data rows -> 83 runs\n",
      "('rcv1', 'SGD') -> 8316 data rows -> 83 runs\n",
      "('rcv1', 'Adam') -> 2079 data rows -> 20 runs\n",
      "('rcv1', 'SARAH') -> 7392 data rows -> 73 runs\n",
      "('rcv1', 'L-SVRG') -> 7392 data rows -> 73 runs\n",
      "('real-sim', 'SGD') -> 7392 data rows -> 73 runs\n",
      "('real-sim', 'Adam') -> 1848 data rows -> 18 runs\n",
      "('real-sim', 'SARAH') -> 7392 data rows -> 73 runs\n",
      "('real-sim', 'L-SVRG') -> 7392 data rows -> 73 runs\n",
      "Took about 39.52 seconds to gather all these data.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data frame lengths:\")\n",
    "for exp, df in all_dfs.items():\n",
    "    print(f\"{exp} -> {len(df)} data rows -> {len(df) // T} runs\")\n",
    "print(f\"Took about {data_gather_time:.2f} seconds to gather all these data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81496a9e-0aa2-4969-a7b2-21081c7e3f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a9a', 'SGD')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>precond</th>\n",
       "      <th>alpha</th>\n",
       "      <th>loss</th>\n",
       "      <th>gradnorm</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1529.465824</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>113.010573</td>\n",
       "      <td>664.831308</td>\n",
       "      <td>0.256550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>122.158834</td>\n",
       "      <td>699.929352</td>\n",
       "      <td>0.261304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>95.213317</td>\n",
       "      <td>830.147837</td>\n",
       "      <td>0.258952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>98.567754</td>\n",
       "      <td>701.136119</td>\n",
       "      <td>0.255896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.344543</td>\n",
       "      <td>0.510958</td>\n",
       "      <td>0.161522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.344926</td>\n",
       "      <td>0.597405</td>\n",
       "      <td>0.161130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.346016</td>\n",
       "      <td>0.913790</td>\n",
       "      <td>0.161501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.343733</td>\n",
       "      <td>0.631168</td>\n",
       "      <td>0.160822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>hutchinson</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.343726</td>\n",
       "      <td>0.602774</td>\n",
       "      <td>0.160700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8316 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ep        lr   BS     precond alpha        loss     gradnorm  \\\n",
       "0       0.0  0.250000  128        none  none    0.693147  1529.465824   \n",
       "1       5.0  0.250000  128        none  none  113.010573   664.831308   \n",
       "2      10.0  0.250000  128        none  none  122.158834   699.929352   \n",
       "3      15.0  0.250000  128        none  none   95.213317   830.147837   \n",
       "4      20.0  0.250000  128        none  none   98.567754   701.136119   \n",
       "...     ...       ...  ...         ...   ...         ...          ...   \n",
       "8311   80.0  0.015625  128  hutchinson   0.1    0.344543     0.510958   \n",
       "8312   85.0  0.015625  128  hutchinson   0.1    0.344926     0.597405   \n",
       "8313   90.0  0.015625  128  hutchinson   0.1    0.346016     0.913790   \n",
       "8314   95.0  0.015625  128  hutchinson   0.1    0.343733     0.631168   \n",
       "8315  100.0  0.015625  128  hutchinson   0.1    0.343726     0.602774   \n",
       "\n",
       "         error  \n",
       "0     0.500000  \n",
       "1     0.256550  \n",
       "2     0.261304  \n",
       "3     0.258952  \n",
       "4     0.255896  \n",
       "...        ...  \n",
       "8311  0.161522  \n",
       "8312  0.161130  \n",
       "8313  0.161501  \n",
       "8314  0.160822  \n",
       "8315  0.160700  \n",
       "\n",
       "[8316 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a9a', 'Adam')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>precond</th>\n",
       "      <th>alpha</th>\n",
       "      <th>loss</th>\n",
       "      <th>gradnorm</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1529.465824</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.435452</td>\n",
       "      <td>70.799062</td>\n",
       "      <td>0.187790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.398886</td>\n",
       "      <td>67.818147</td>\n",
       "      <td>0.176218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.404162</td>\n",
       "      <td>88.323849</td>\n",
       "      <td>0.176607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.393879</td>\n",
       "      <td>54.472134</td>\n",
       "      <td>0.172675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.583387</td>\n",
       "      <td>140.991985</td>\n",
       "      <td>0.188742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.570388</td>\n",
       "      <td>125.247746</td>\n",
       "      <td>0.188475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.544347</td>\n",
       "      <td>117.218403</td>\n",
       "      <td>0.186919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.589378</td>\n",
       "      <td>173.168942</td>\n",
       "      <td>0.190157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.518594</td>\n",
       "      <td>97.748811</td>\n",
       "      <td>0.184625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ep        lr   BS precond alpha      loss     gradnorm     error\n",
       "0       0.0  0.015625  128    none  none  0.693147  1529.465824  0.500000\n",
       "1       5.0  0.015625  128    none  none  0.435452    70.799062  0.187790\n",
       "2      10.0  0.015625  128    none  none  0.398886    67.818147  0.176218\n",
       "3      15.0  0.015625  128    none  none  0.404162    88.323849  0.176607\n",
       "4      20.0  0.015625  128    none  none  0.393879    54.472134  0.172675\n",
       "...     ...       ...  ...     ...   ...       ...          ...       ...\n",
       "2074   80.0  0.062500  128    none  none  0.583387   140.991985  0.188742\n",
       "2075   85.0  0.062500  128    none  none  0.570388   125.247746  0.188475\n",
       "2076   90.0  0.062500  128    none  none  0.544347   117.218403  0.186919\n",
       "2077   95.0  0.062500  128    none  none  0.589378   173.168942  0.190157\n",
       "2078  100.0  0.062500  128    none  none  0.518594    97.748811  0.184625\n",
       "\n",
       "[2079 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a9a', 'SARAH')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep</th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>precond</th>\n",
       "      <th>alpha</th>\n",
       "      <th>loss</th>\n",
       "      <th>gradnorm</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>840.928096</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>170038.319924</td>\n",
       "      <td>757.545785</td>\n",
       "      <td>0.305833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>23089.423052</td>\n",
       "      <td>612.062111</td>\n",
       "      <td>0.323217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>28242.598214</td>\n",
       "      <td>553.153684</td>\n",
       "      <td>0.285293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>17606.615604</td>\n",
       "      <td>286.914670</td>\n",
       "      <td>0.291054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8180</th>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>7896.344815</td>\n",
       "      <td>994.151625</td>\n",
       "      <td>0.346751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>7383.777889</td>\n",
       "      <td>208.110324</td>\n",
       "      <td>0.271292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>85.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>3352.979973</td>\n",
       "      <td>144.781995</td>\n",
       "      <td>0.248543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>3634.551796</td>\n",
       "      <td>109.708327</td>\n",
       "      <td>0.228397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>95.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>5417.068005</td>\n",
       "      <td>237.594469</td>\n",
       "      <td>0.252587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8185 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ep   lr   BS precond alpha           loss    gradnorm     error\n",
       "0      0.0  4.0  128    none  none       0.693147  840.928096  0.500000\n",
       "1      5.0  4.0  128    none  none  170038.319924  757.545785  0.305833\n",
       "2     10.0  4.0  128    none  none   23089.423052  612.062111  0.323217\n",
       "3     15.0  4.0  128    none  none   28242.598214  553.153684  0.285293\n",
       "4     20.0  4.0  128    none  none   17606.615604  286.914670  0.291054\n",
       "...    ...  ...  ...     ...   ...            ...         ...       ...\n",
       "8180  75.0  4.0  128    none  none    7896.344815  994.151625  0.346751\n",
       "8181  80.0  4.0  128    none  none    7383.777889  208.110324  0.271292\n",
       "8182  85.0  4.0  128    none  none    3352.979973  144.781995  0.248543\n",
       "8183  90.0  4.0  128    none  none    3634.551796  109.708327  0.228397\n",
       "8184  95.0  4.0  128    none  none    5417.068005  237.594469  0.252587\n",
       "\n",
       "[8185 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (exp, df) in enumerate(all_dfs.items()):\n",
    "    if i == 3: break\n",
    "    print(exp)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98f3f7-60e4-403b-92b8-795d8067e530",
   "metadata": {},
   "source": [
    "## Get best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca59c937-0832-4f7f-a48e-2e39b74d05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dfs = {}\n",
    "best_dfs_with_precond = {}\n",
    "best_dfs_without_precond = {}\n",
    "for exp in product(DATASETS, OPTIMIZERS):\n",
    "    exp_df = all_dfs[exp]\n",
    "    # Get last metrics/performance  @TODO: is this good?\n",
    "    max_ep = exp_df.groupby(ARG_COLS, sort=False)[\"ep\"].transform(max)\n",
    "    perf = exp_df[exp_df[\"ep\"] == max_ep].drop(\"ep\", axis=1)\n",
    "    # Find the minimum aggregate metric (based on mean, median, etc.)\n",
    "    def find_best_hyperparams(perf):\n",
    "        if AGG == \"mean\":\n",
    "            agg_perf = perf.groupby(ARG_COLS).mean()\n",
    "        elif AGG == \"median\":\n",
    "            agg_perf = perf.groupby(ARG_COLS).median()\n",
    "        # Get the aggregated perf that minimizes the chosen metric\n",
    "        min_agg_perf = agg_perf[agg_perf[METRIC] == agg_perf.min()[METRIC]]\n",
    "        return min_agg_perf.index\n",
    "    # Get the data associated with the args of the min aggregated metric\n",
    "    exp_df = exp_df.set_index(ARG_COLS)\n",
    "    best_dfs[exp] = exp_df.loc[find_best_hyperparams(perf)]\n",
    "    best_dfs_with_precond[exp] = exp_df.loc[find_best_hyperparams(perf[perf[\"precond\"] == \"hutchinson\"])]\n",
    "    best_dfs_without_precond[exp] = exp_df.loc[find_best_hyperparams(perf[perf[\"precond\"] == \"none\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d9874c-6a23-45c9-80f0-67bebd27b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparams for each optimizer on each dataset given the following setting:\n",
      "{'corrupt': '(-3,3)', 'weight_decay': 0}\n",
      "\n",
      "('a9a', 'SGD')\n",
      "- lr = 2**-10\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('a9a', 'Adam')\n",
      "- lr = 2**-16\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('a9a', 'SARAH')\n",
      "- lr = 2**-6\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('a9a', 'L-SVRG')\n",
      "- lr = 2**-4\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('w8a', 'SGD')\n",
      "- lr = 2**-12\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.001\n",
      "\n",
      "('w8a', 'Adam')\n",
      "- lr = 2**-16\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('w8a', 'SARAH')\n",
      "- lr = 2**-8\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('w8a', 'L-SVRG')\n",
      "- lr = 2**-6\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('rcv1', 'SGD')\n",
      "- lr = 2**-10\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.001\n",
      "\n",
      "('rcv1', 'Adam')\n",
      "- lr = 2**-14\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('rcv1', 'SARAH')\n",
      "- lr = 2**-8\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('rcv1', 'L-SVRG')\n",
      "- lr = 2**-8\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('real-sim', 'SGD')\n",
      "- lr = 2**-12\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.001\n",
      "\n",
      "('real-sim', 'Adam')\n",
      "- lr = 2**-16\n",
      "- BS = 128\n",
      "- precond = none\n",
      "- alpha = none\n",
      "\n",
      "('real-sim', 'SARAH')\n",
      "- lr = 2**-10\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n",
      "('real-sim', 'L-SVRG')\n",
      "- lr = 2**-8\n",
      "- BS = 128\n",
      "- precond = hutchinson\n",
      "- alpha = 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparams for each optimizer on each dataset given the following setting:\")\n",
    "print(FILTER_ARGS)\n",
    "print()\n",
    "for exp, df in best_dfs.items():\n",
    "    print(exp)\n",
    "    for arg, val in zip(ARG_COLS, df.index[0]):\n",
    "        if arg == \"lr\":\n",
    "            val = \"2**\" + str(int(log2(val)))\n",
    "        print(f\"- {arg} = {val}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bb07b",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fd0ff",
   "metadata": {},
   "source": [
    "## Plot gradnorm per lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "161b091b-9c0a-48e0-9f37-7ab51ade0273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types\n",
      "ep float64\n",
      "loss float64\n",
      "gradnorm float64\n",
      "error float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Types\")\n",
    "for col in df.columns:\n",
    "    print(col, df[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7f87599-2e6b-4030-b71e-2455347d9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rates:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2**-10',\n",
       " '2**-12',\n",
       " '2**-14',\n",
       " '2**-16',\n",
       " '2**-2',\n",
       " '2**-4',\n",
       " '2**-6',\n",
       " '2**-8',\n",
       " '2**0',\n",
       " '2**2',\n",
       " '2**4'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Learning rates:\")\n",
    "for exp, df in all_dfs.items():\n",
    "    display(set(\"2**\"+str(int(log2(lr))) for lr in df[\"lr\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "329af229-7514-43cf-a3b8-013508e623f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range\n",
      "ep: (0.0, 100.0)\n",
      "lr: (1.52587890625e-05, 16.0)\n",
      "BS: (128, 128)\n",
      "loss: (0.33428567783858903, 190231207821.8668)\n",
      "gradnorm: (0.007554754362071744, 7014.391853635776)\n",
      "error: (0.15514598241249758, 0.5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Range\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes != \"object\":\n",
    "        print(f\"{col}: ({df[col].min():}, {df[col].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2b7628b-1e89-482a-9cdc-055e14187188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: (0.0, 100.0)\n",
      "lr: (1.52587890625e-05, 16.0)\n",
      "BS: (128, 128)\n",
      "loss: (0.33428567783858903, 190231207821.8668)\n",
      "gradnorm: (0.007554754362071744, 7014.391853635776)\n",
      "error: (0.15514598241249758, 0.5)\n"
     ]
    }
   ],
   "source": [
    "# Set inf values to nan and recheck range\n",
    "VERYBIGNUMBER = 10**20\n",
    "df[df == float(\"inf\")] = np.nan\n",
    "df[df[[\"loss\",\"gradnorm\"]] > VERYBIGNUMBER] = np.nan\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes != \"object\":\n",
    "        print(f\"{col}: ({df[col].min():}, {df[col].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "302e0f60-db61-4ed7-bf7f-7f38f554a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for NaNs in each column for each df.\n",
      "ep\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "lr\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "BS\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "precond\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "alpha\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "loss\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "gradnorm\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n",
      "error\n",
      "- ('a9a', 'SGD'): 0\n",
      "- ('a9a', 'Adam'): 0\n",
      "- ('a9a', 'SARAH'): 0\n",
      "- ('a9a', 'L-SVRG'): 0\n",
      "- ('w8a', 'SGD'): 0\n",
      "- ('w8a', 'Adam'): 0\n",
      "- ('w8a', 'SARAH'): 0\n",
      "- ('w8a', 'L-SVRG'): 0\n",
      "- ('rcv1', 'SGD'): 0\n",
      "- ('rcv1', 'Adam'): 0\n",
      "- ('rcv1', 'SARAH'): 0\n",
      "- ('rcv1', 'L-SVRG'): 0\n",
      "- ('real-sim', 'SGD'): 0\n",
      "- ('real-sim', 'Adam'): 0\n",
      "- ('real-sim', 'SARAH'): 0\n",
      "- ('real-sim', 'L-SVRG'): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Check for NaNs in each column for each df.\")\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    for exp, df in all_dfs.items():\n",
    "        print(f\"- {exp}: {df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a63dddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for ('a9a', 'SGD')...\n",
      "Plotting lines for ('w8a', 'SGD')...\n",
      "Plotting lines for ('rcv1', 'SGD')...\n",
      "Plotting lines for ('real-sim', 'SGD')...\n",
      "Plotting lines for ('a9a', 'Adam')...\n",
      "Plotting lines for ('w8a', 'Adam')...\n",
      "Plotting lines for ('rcv1', 'Adam')...\n",
      "Plotting lines for ('real-sim', 'Adam')...\n",
      "Plotting lines for ('a9a', 'SARAH')...\n",
      "Plotting lines for ('w8a', 'SARAH')...\n",
      "Plotting lines for ('rcv1', 'SARAH')...\n",
      "Plotting lines for ('real-sim', 'SARAH')...\n",
      "Plotting lines for ('a9a', 'L-SVRG')...\n",
      "Plotting lines for ('w8a', 'L-SVRG')...\n",
      "Plotting lines for ('rcv1', 'L-SVRG')...\n",
      "Plotting lines for ('real-sim', 'L-SVRG')...\n",
      "Took about 159.08 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Plot data for all optim, datasets, and args\n",
    "fig, axes = plt.subplots(len(OPTIMIZERS), len(DATASETS))\n",
    "fig.set_size_inches(5 * len(DATASETS), 5 * len(OPTIMIZERS))\n",
    "title = r\"$||\\nabla F(w_t)||^2$ per $\\eta$\"\n",
    "plt.suptitle(title)\n",
    "for i, optimizer in enumerate(OPTIMIZERS):\n",
    "    for j, dataset in enumerate(DATASETS):\n",
    "        exp = (dataset, optimizer)\n",
    "        if exp not in all_dfs:\n",
    "            continue\n",
    "        exp_df = all_dfs[exp]\n",
    "        axes[i,j].set_title(rf\"$\\tt{optimizer}({dataset})$\")\n",
    "        # axes[i,j].set_title(rf\"{optimizer}({dataset})\")\n",
    "        # avoid silly problem of inconsistent style across axes\n",
    "        exp_df[\"alpha\"] = exp_df[\"alpha\"].astype(str)\n",
    "        exp_df = exp_df.sort_values(\"alpha\", ascending=False)\n",
    "        print(f\"Plotting lines for {exp}...\")\n",
    "        sns.lineplot(ax=axes[i,j], x=\"ep\", y=\"gradnorm\",\n",
    "                     hue=\"lr\", hue_norm=LogNorm(), palette=\"vlag\",\n",
    "                     #size=\"BS\", sizes=(1, 2),  # @XXX\n",
    "                     style=\"alpha\",\n",
    "                     # plot only for alpha == none and alpha == 0.001 to reduce clutter\n",
    "                     data=exp_df[(exp_df[\"alpha\"] == \"none\") | (exp_df[\"alpha\"] == \"0.001\")])\n",
    "        axes[i,j].set(yscale=\"log\")\n",
    "        axes[i,j].set_ylabel(r\"$||\\nabla F(w_t)||^2$\")\n",
    "        # Set an upper limit since we seem to have crazy values for some runs @TODO: remove those runs?\n",
    "        axes[i,j].set_ylim(top=exp_df[exp_df[\"ep\"] == 0][\"gradnorm\"].max())\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create a string out of filter args and save figure\n",
    "filter_args_str = \",\".join(f\"{k}={v}\" for k,v in FILTER_ARGS.items())\n",
    "plt.savefig(f\"plots/learning_rates({filter_args_str}).pdf\")\n",
    "plt.close()\n",
    "plot_per_lr_time = time.time() - start_time\n",
    "print(f\"Took about {plot_per_lr_time:.2f} seconds to create this plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130b8ea",
   "metadata": {},
   "source": [
    "## Plot best performance of each optimizer on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af103b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for ('a9a', 'SGD')...\n",
      "Plotting lines for ('a9a', 'Adam')...\n",
      "Plotting lines for ('a9a', 'SARAH')...\n",
      "Plotting lines for ('a9a', 'L-SVRG')...\n",
      "Plotting lines for ('w8a', 'SGD')...\n",
      "Plotting lines for ('w8a', 'Adam')...\n",
      "Plotting lines for ('w8a', 'SARAH')...\n",
      "Plotting lines for ('w8a', 'L-SVRG')...\n",
      "Plotting lines for ('rcv1', 'SGD')...\n",
      "Plotting lines for ('rcv1', 'Adam')...\n",
      "Plotting lines for ('rcv1', 'SARAH')...\n",
      "Plotting lines for ('rcv1', 'L-SVRG')...\n",
      "Plotting lines for ('real-sim', 'SGD')...\n",
      "Plotting lines for ('real-sim', 'Adam')...\n",
      "Plotting lines for ('real-sim', 'SARAH')...\n",
      "Plotting lines for ('real-sim', 'L-SVRG')...\n",
      "Took about 27.13 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Plot 3 rows each one showing some performance metric,\n",
    "# where the columns are the dataset on which the optim is run.\n",
    "fig, axes = plt.subplots(3, len(DATASETS))\n",
    "fig.set_size_inches(5 * len(DATASETS), 5 * 3)\n",
    "plt.suptitle(rf\"Best Performances\")\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "    for optimizer in OPTIMIZERS:\n",
    "        exp = (dataset, optimizer)\n",
    "        if exp not in best_dfs:\n",
    "            continue\n",
    "        # Get hyperparams of best performance of 'optimizer' on 'dataset'\n",
    "        args = {k:v for k,v in zip(best_dfs[exp].index.names, best_dfs[exp].index[0])}\n",
    "        exp_df = best_dfs[exp].reset_index()\n",
    "        # Show power of lr as 2^lr_pow\n",
    "        lr_pow = round(log2(args['lr']))\n",
    "        sublabel = rf\"$\\eta = 2^{{{lr_pow}}}$, $\\alpha={args['alpha']}$\"\n",
    "        label = rf\"{optimizer}({sublabel})\"\n",
    "        print(f\"Plotting lines for {exp}...\")\n",
    "        sns.lineplot(x=\"ep\", y=\"loss\", label=label, ax=axes[0,j], data=exp_df)\n",
    "        sns.lineplot(x=\"ep\", y=\"gradnorm\", label=label, ax=axes[1,j], data=exp_df)\n",
    "        sns.lineplot(x=\"ep\", y=\"error\", label=label, ax=axes[2,j], data=exp_df)\n",
    "    # Loss\n",
    "    axes[0,j].set_title(dataset)\n",
    "    axes[0,j].set_ylabel(r\"$F(w_t)$\")\n",
    "    axes[0,j].set_xlabel(\"Effective Passes\")\n",
    "    axes[0,j].legend()\n",
    "    # Gradnorm\n",
    "    axes[1,j].set(yscale=\"log\")\n",
    "    axes[1,j].set_title(dataset)\n",
    "    axes[1,j].set_ylabel(r\"$||\\nabla F(w_t)||^2$\")\n",
    "    axes[1,j].set_xlabel(\"Effective Passes\")\n",
    "    axes[1,j].legend()\n",
    "    # Error\n",
    "    axes[2,j].set(yscale=\"log\")\n",
    "    axes[2,j].set_title(dataset)\n",
    "    axes[2,j].set_ylabel(\"Error\")\n",
    "    axes[2,j].set_xlabel(\"Effective Passes\")\n",
    "    axes[2,j].legend()\n",
    "    # Set an upper limit since we seem to have crazy values for some runs @TODO: remove those runs?\n",
    "    # axes[0,j].set_ylim(top=exp_df[exp_df[\"ep\"] == 0][\"loss\"].max()*1.1,\n",
    "                       # bottom=exp_df[\"loss\"].min()*0.9)\n",
    "    axes[1,j].set_ylim(top=exp_df[exp_df[\"ep\"] == 0][\"gradnorm\"].max())\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create a string out of filter args and save figure\n",
    "filter_args_str = \",\".join(f\"{k}={v}\" for k,v in FILTER_ARGS.items())\n",
    "plt.savefig(f\"plots/optimizers({filter_args_str}).pdf\")\n",
    "plt.close()\n",
    "plot_best_time = time.time() - start_time\n",
    "print(f\"Took about {plot_best_time:.2f} seconds to create this plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fe2bc",
   "metadata": {},
   "source": [
    "# Generate plots comparing preconditioning vs none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dbbfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting lines for a9a...\n",
      "Plotting lines for w8a...\n",
      "Plotting lines for rcv1...\n",
      "Plotting lines for real-sim...\n",
      "Took about 50.53 seconds to create this plot.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "fig, axes = plt.subplots(3, len(DATASETS))\n",
    "fig.set_size_inches(5 * len(DATASETS), 5 * 3)\n",
    "plt.suptitle(rf\"Top performance with preconditioning vs. without\")\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "    optim_df = pd.DataFrame()\n",
    "    for optimizer in OPTIMIZERS:\n",
    "        exp = (dataset, optimizer)\n",
    "        if exp not in best_dfs_with_precond or exp not in best_dfs_without_precond:\n",
    "            continue\n",
    "        # Put both dfs together and mark them with the optimizer's name.\n",
    "        # (They already have 'precond' set accordingly.)\n",
    "        exp_df = best_dfs_without_precond[exp].append(best_dfs_with_precond[exp])\n",
    "        exp_df[\"optimizer\"] = optimizer\n",
    "        optim_df = optim_df.append(exp_df)\n",
    "    # reset index and combine precond with gamma\n",
    "    print(f\"Plotting lines for {dataset}...\")\n",
    "    optim_df = optim_df.reset_index()\n",
    "    sns.lineplot(x=\"ep\", y=\"loss\", hue=\"optimizer\", style=\"precond\", ax=axes[0,j], data=optim_df)\n",
    "    sns.lineplot(x=\"ep\", y=\"gradnorm\", hue=\"optimizer\", style=\"precond\", ax=axes[1,j], data=optim_df)\n",
    "    sns.lineplot(x=\"ep\", y=\"error\", hue=\"optimizer\", style=\"precond\", ax=axes[2,j], data=optim_df)\n",
    "    # Loss\n",
    "    axes[0,j].set_title(dataset)\n",
    "    axes[0,j].set_ylabel(r\"$F(w_t)$\")\n",
    "    axes[0,j].set_xlabel(\"Effective Passes\")\n",
    "    # Gradnorm\n",
    "    axes[1,j].set(yscale=\"log\")\n",
    "    axes[1,j].set_title(dataset)\n",
    "    axes[1,j].set_ylabel(r\"$||\\nabla F(w_t)||^2$\")\n",
    "    axes[1,j].set_xlabel(\"Effective Passes\")\n",
    "    # Error\n",
    "    axes[2,j].set(yscale=\"log\")\n",
    "    axes[2,j].set_title(dataset)\n",
    "    axes[2,j].set_ylabel(\"Error\")\n",
    "    axes[2,j].set_xlabel(\"Effective Passes\")\n",
    "fig.tight_layout()\n",
    "\n",
    "filter_args_str = \",\".join(f\"{k}={v}\" for k,v in FILTER_ARGS.items())\n",
    "plt.savefig(f\"plots/compare_optimizers({filter_args_str}).pdf\")\n",
    "plt.close()\n",
    "plot_compare_time = time.time() - start_time\n",
    "print(f\"Took about {plot_compare_time:.2f} seconds to create this plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9fec6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters using gradnorm metric WITHOUT preconditoning:\n",
      "('a9a', 'SGD'):\tlr = 2^-16,\tloss = 0.425640,\tgradnorm = 0.345316,\terror = 0.201449\n",
      "('a9a', 'Adam'):\tlr = 2^-16,\tloss = 0.384308,\tgradnorm = 0.154609,\terror = 0.179367\n",
      "('a9a', 'SARAH'):\tlr = 2^-10,\tloss = 0.400594,\tgradnorm = 0.000804,\terror = 0.187749\n",
      "('a9a', 'L-SVRG'):\tlr = 2^-14,\tloss = 0.484843,\tgradnorm = 0.015331,\terror = 0.220827\n",
      "('w8a', 'SGD'):\tlr = 2^-14,\tloss = 0.197371,\tgradnorm = 0.016864,\terror = 0.062160\n",
      "('w8a', 'Adam'):\tlr = 2^-16,\tloss = 0.162432,\tgradnorm = 0.004597,\terror = 0.061150\n",
      "('w8a', 'SARAH'):\tlr = 2^-10,\tloss = 0.168572,\tgradnorm = 0.000344,\terror = 0.063900\n",
      "('w8a', 'L-SVRG'):\tlr = 2^-10,\tloss = 0.179330,\tgradnorm = 0.001024,\terror = 0.062263\n",
      "('rcv1', 'SGD'):\tlr = 2^-12,\tloss = 0.170175,\tgradnorm = 0.035876,\terror = 0.057769\n",
      "('rcv1', 'Adam'):\tlr = 2^-14,\tloss = 0.056230,\tgradnorm = 0.002812,\terror = 0.015777\n",
      "('rcv1', 'SARAH'):\tlr = 2^-8,\tloss = 0.105435,\tgradnorm = 0.000867,\terror = 0.034058\n",
      "('rcv1', 'L-SVRG'):\tlr = 2^-8,\tloss = 0.103144,\tgradnorm = 0.001080,\terror = 0.031650\n",
      "('real-sim', 'SGD'):\tlr = 2^-12,\tloss = 0.180173,\tgradnorm = 0.012132,\terror = 0.066412\n",
      "('real-sim', 'Adam'):\tlr = 2^-16,\tloss = 0.102593,\tgradnorm = 0.001429,\terror = 0.036055\n",
      "('real-sim', 'SARAH'):\tlr = 2^-8,\tloss = 0.112298,\tgradnorm = 0.000606,\terror = 0.041251\n",
      "('real-sim', 'L-SVRG'):\tlr = 2^-8,\tloss = 0.155489,\tgradnorm = 0.000694,\terror = 0.057337\n",
      "\n",
      "Best hyperparameters using gradnorm metric WITH preconditoning:\n",
      "('a9a', 'SGD'):\tlr = 2^-10,\talpha = 0.1,\tloss = 0.354579,\tgradnorm = 0.121555,\terror = 0.162705\n",
      "('a9a', 'SARAH'):\tlr = 2^-6,\talpha = 0.1,\tloss = 0.345365,\tgradnorm = 0.000035,\terror = 0.162577\n",
      "('a9a', 'L-SVRG'):\tlr = 2^-4,\talpha = 0.1,\tloss = 0.362135,\tgradnorm = 0.000011,\terror = 0.166580\n",
      "('w8a', 'SGD'):\tlr = 2^-12,\talpha = 0.001,\tloss = 0.139636,\tgradnorm = 0.001052,\terror = 0.060001\n",
      "('w8a', 'SARAH'):\tlr = 2^-8,\talpha = 0.1,\tloss = 0.147959,\tgradnorm = 0.000007,\terror = 0.059275\n",
      "('w8a', 'L-SVRG'):\tlr = 2^-6,\talpha = 0.1,\tloss = 0.145717,\tgradnorm = 0.000004,\terror = 0.059318\n",
      "('rcv1', 'SGD'):\tlr = 2^-10,\talpha = 0.001,\tloss = 0.019292,\tgradnorm = 0.002542,\terror = 0.002824\n",
      "('rcv1', 'SARAH'):\tlr = 2^-8,\talpha = 0.1,\tloss = 0.059077,\tgradnorm = 0.000083,\terror = 0.017090\n",
      "('rcv1', 'L-SVRG'):\tlr = 2^-8,\talpha = 0.1,\tloss = 0.050445,\tgradnorm = 0.000116,\terror = 0.013902\n",
      "('real-sim', 'SGD'):\tlr = 2^-12,\talpha = 0.001,\tloss = 0.059649,\tgradnorm = 0.001209,\terror = 0.021357\n",
      "('real-sim', 'SARAH'):\tlr = 2^-10,\talpha = 0.1,\tloss = 0.108786,\tgradnorm = 0.000063,\terror = 0.040839\n",
      "('real-sim', 'L-SVRG'):\tlr = 2^-8,\talpha = 0.1,\tloss = 0.091064,\tgradnorm = 0.000041,\terror = 0.033219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_best_performances(best_data, show_alpha=True):\n",
    "    for dataset in DATASETS:\n",
    "        for optimizer in OPTIMIZERS:\n",
    "            # Extract best performance metrics for each experiment\n",
    "            exp = (dataset, optimizer)\n",
    "            if exp not in best_data:\n",
    "                continue\n",
    "            if len(best_data[exp].index) == 0:\n",
    "                # Not applicable to exp, likely because it does not have 'precond'\n",
    "                continue\n",
    "            args = {k:v for k,v in zip(best_data[exp].index.names, best_data[exp].index[0])}\n",
    "            exp_df = best_data[exp].reset_index()\n",
    "            loss = exp_df[\"loss\"].iloc[-1]\n",
    "            gradnorm = exp_df[\"gradnorm\"].iloc[-1]\n",
    "            error = exp_df[\"error\"].iloc[-1]\n",
    "            # Print report\n",
    "            print(f\"{exp}:\"\n",
    "                  f\"\\tlr = 2^{str(round(log2(args['lr'])))},\" + \\\n",
    "                  (f\"\\talpha = {args['alpha']},\" if show_alpha else \"\") + \\\n",
    "                  f\"\\tloss = {loss:5f},\"\n",
    "                  f\"\\tgradnorm = {gradnorm:5f},\"\n",
    "                  f\"\\terror = {error:5f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"Best hyperparameters using {METRIC} metric WITHOUT preconditoning:\")\n",
    "display_best_performances(best_dfs_without_precond, show_alpha=False)\n",
    "print(f\"Best hyperparameters using {METRIC} metric WITH preconditoning:\")\n",
    "display_best_performances(best_dfs_with_precond, show_alpha=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85397467-886c-4ae1-9cbc-4f10f26b3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
